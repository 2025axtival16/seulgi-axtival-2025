"use client";

import React, { useState, useEffect, useRef, useMemo } from "react";
import { Mic, MicOff, Volume2, AlertCircle } from "lucide-react";
import { sprinkles } from "../../styles/sprinkles.css";
import * as SpeechSDK from "microsoft-cognitiveservices-speech-sdk";
import { formatTimeFromDate } from "../../utils/timeFormat";
import { SPEECH_KEY, SPEECH_REGION, API_BASE_URL } from "../../constants/KEY";

interface TranscriptItem {
  id: string;
  speaker: string;
  content: string;
  timestamp: Date;
  isPartial?: boolean;
}

interface Employee {
  id: string;
  name: string;
  email: string;
}

interface TranscriptionAreaProps {
  title?: string;
  isRecording: boolean;
  isPaused: boolean;
  participants: Employee[];
  onTranscriptUpdate: (transcript: TranscriptItem[]) => void;
  onRecordingStart: (startTime: Date) => void;
  onRealTimeSummaryUpdate: (summary: string) => void;
  onLogsUpdate: (logs: string[]) => void;
}

const TranscriptionArea: React.FC<TranscriptionAreaProps> = ({
  title,
  isRecording,
  isPaused,
  participants,
  onTranscriptUpdate,
  onRecordingStart,
  onRealTimeSummaryUpdate,
  onLogsUpdate,
}) => {
  const [transcript, setTranscript] = useState<TranscriptItem[]>([]);
  const [logs, setLogs] = useState<string[]>([]);
  const [isListening, setIsListening] = useState(false);
  const [currentSpeaker, setCurrentSpeaker] = useState<string>("");
  const [error, setError] = useState<string>("");

  // ì°¸ì¡°
  const transcriberRef = useRef<SpeechSDK.ConversationTranscriber | null>(null);
  const speechConfigRef = useRef<SpeechSDK.SpeechConfig>();
  const speakers = useRef<Record<string, string>>({});
  const transcriptEndRef = useRef<HTMLDivElement>(null);
  const logsRef = useRef<string[]>([]);
  const isPausedRef = useRef<boolean>(isPaused);
  const logCountRef = useRef<number>(0);

  // ì°¸ê°€ì ë¼ë²¨ ë§¤í•‘
  const { participantsList, labelMap } = useMemo(() => {
    const list = participants.map((p) => p.name);
    const map: Record<string, string> = {};
    list.forEach((name, idx) => {
      map[String.fromCharCode(65 + idx)] = name;
    });
    return { participantsList: list, labelMap: map };
  }, [participants]);

  // isPaused ref ì—…ë°ì´íŠ¸ ë° í™”ì ìƒíƒœ í´ë¦¬ì–´
  useEffect(() => {
    isPausedRef.current = isPaused;
    if (isPaused) {
      setCurrentSpeaker(""); // ì¼ì‹œì •ì§€ ì‹œ í˜„ì¬ í™”ì í´ë¦¬ì–´
    }
  }, [isPaused]);

  // Speech Config ì´ˆê¸°í™”
  useEffect(() => {
    const initializeSpeechConfig = () => {
      try {
        const config = SpeechSDK.SpeechConfig.fromSubscription(
          SPEECH_KEY,
          SPEECH_REGION
        );
        config.speechRecognitionLanguage = "ko-KR";
        speechConfigRef.current = config;
        setError("");
      } catch (err) {
        console.error("Speech SDK ì´ˆê¸°í™” ì‹¤íŒ¨:", err);
        setError("Speech SDK ì´ˆê¸°í™” ì‹¤íŒ¨ - SPEECH_KEYë¥¼ í™•ì¸í•˜ì„¸ìš”");
      }
    };

    initializeSpeechConfig();
  }, []);

  // ìš”ì•½ API í˜¸ì¶œ í•¨ìˆ˜
  const callSummaryAPI = async (logs: string[]) => {
    try {
      // ì‹œìŠ¤í…œ ë©”ì‹œì§€ê°€ ì•„ë‹Œ ì‹¤ì œ ëŒ€í™” ë‚´ìš©ë§Œ ì¶”ì¶œ
      const conversationLogs = logs.filter(
        (log) =>
          !log.includes("ğŸ¤") &&
          !log.includes("ğŸ›‘") &&
          !log.includes("â¸ï¸") &&
          !log.includes("â–¶ï¸") &&
          !log.includes("âŒ")
      );

      if (conversationLogs.length === 0) return;

      const response = await fetch(`${API_BASE_URL}/summary`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          title: title,
          text: logs.join("\n"),
        }),
      });

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      const data = await response.json();
      console.log("ğŸ“Š API ì‘ë‹µ ë°ì´í„°:", data);

      if (data.answer) {
        console.log("âœ… ìš”ì•½ ë°›ìŒ:", data.answer);
        onRealTimeSummaryUpdate(data.answer);
      } else {
        console.log("âŒ ìš”ì•½ ë°ì´í„°ê°€ ì—†ìŒ, ì‘ë‹µ êµ¬ì¡°:", Object.keys(data));
      }
    } catch (error) {
      console.error("ğŸ’¥ ìš”ì•½ API í˜¸ì¶œ ì‹¤íŒ¨:", error);
    }
  };

  // ë¡œê·¸ ì¶”ê°€ í•¨ìˆ˜
  const appendLog = (line: string) => {
    const next = [...logsRef.current, line];
    logsRef.current = next;
    setLogs(next);
    onLogsUpdate(next); // ìƒìœ„ ì»´í¬ë„ŒíŠ¸ì— ë¡œê·¸ ì—…ë°ì´íŠ¸ ì „ë‹¬
    console.log("next", next);

    // ë¡œê·¸ ì¹´ìš´í„° ì¦ê°€ (ì‹œìŠ¤í…œ ë©”ì‹œì§€ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ)
    const isSystemMessage =
      line.includes("ğŸ¤") ||
      line.includes("ğŸ›‘") ||
      line.includes("â¸ï¸") ||
      line.includes("â–¶ï¸") ||
      line.includes("âŒ");

    if (!isSystemMessage) {
      logCountRef.current += 1;
      console.log("ğŸ’¬ í˜„ì¬ ë¡œê·¸ ì¹´ìš´íŠ¸:", logCountRef.current);

      // 5ê°œë§ˆë‹¤ ìš”ì•½ API í˜¸ì¶œ (í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë‚®ì¶¤)
      if (logCountRef.current >= 5) {
        console.log("ğŸ”¥ 5ê°œ ë¡œê·¸ ëˆ„ì ! ìš”ì•½ API í˜¸ì¶œí•©ë‹ˆë‹¤.");
        callSummaryAPI(logsRef.current);
        logCountRef.current = 0; // ì¹´ìš´í„° ë¦¬ì…‹
      }
    }

    // TranscriptItemìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ìƒìœ„ ì»´í¬ë„ŒíŠ¸ì— ì „ë‹¬
    const transcriptItems = next
      .map((log, index) => {
        const timeMatch = log.match(/^\[(\d{2}:\d{2}:\d{2})\]/);
        const speakerMatch = log.match(/\[([^\]]+)\]/g);
        const speaker =
          speakerMatch && speakerMatch.length > 1
            ? speakerMatch[1].replace(/[\[\]]/g, "")
            : "Unknown Speaker";
        const content = log.replace(/^\[.*?\]\[.*?\]\s/, "");

        return {
          id: `${Date.now()}-${index}`,
          speaker,
          content,
          timestamp: new Date(),
          isPartial: false,
        };
      })
      .filter((item) => item.content); // ë¹ˆ ë‚´ìš© ì œì™¸

    setTranscript(transcriptItems);
    onTranscriptUpdate(transcriptItems);
  };

  // ConversationTranscriber ìƒì„±
  const createTranscriber = (): SpeechSDK.ConversationTranscriber | null => {
    onLogsUpdate([]);
    const speechConfig = speechConfigRef.current;
    if (!speechConfig) {
      console.error("Speech config not initialized");
      return null;
    }

    const audioConfig = SpeechSDK.AudioConfig.fromDefaultMicrophoneInput();
    const transcriber = new SpeechSDK.ConversationTranscriber(
      speechConfig,
      audioConfig
    );

    transcriber.transcribed = (_s: any, evt: any) => {
      // ì¼ì‹œì •ì§€ ìƒíƒœì—ì„œëŠ” ì „ì‚¬ ê²°ê³¼ë¥¼ ë¬´ì‹œ
      if (isPausedRef.current) {
        return;
      }

      const result = evt.result;
      const time = formatTimeFromDate(new Date());
      if (result.reason === SpeechSDK.ResultReason.RecognizedSpeech) {
        const id = result.speakerId!;
        if (!speakers.current[id]) {
          speakers.current[id] = String.fromCharCode(
            65 + Object.keys(speakers.current).length
          );
        }
        const label = speakers.current[id];
        const name = `í™”ì ${label}`;
        appendLog(`[${time}][${name}] ${result.text}`);
        setCurrentSpeaker(name);
      }
    };

    // ìë™ ì¬ì‹œì‘ í•¸ë“¤ëŸ¬
    const restartHandler = async (_s: any, evt: any) => {
      console.warn("ğŸš¨ Speech SDK ì´ë²¤íŠ¸ ë°œìƒ:", evt);
      appendLog("â¸ï¸ ìŒì„± ì¸ì‹ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ìë™ ì¬ì‹œì‘ ì¤€ë¹„ ì¤‘...");

      try {
        if (transcriberRef.current) {
          // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì •ë¦¬
          transcriberRef.current.transcribed = () => {}; // ë¹ˆ í•¨ìˆ˜ë¡œ ì´ë²¤íŠ¸ ë¬´ì‹œ
          transcriberRef.current.canceled = () => {}; // ë¹ˆ í•¨ìˆ˜ë¡œ ì´ë²¤íŠ¸ ë¬´ì‹œ
          await transcriberRef.current.stopTranscribingAsync();
          transcriberRef.current = null;
        }

        // Speech Config ì¬ìƒì„±
        const config = SpeechSDK.SpeechConfig.fromSubscription(
          SPEECH_KEY,
          SPEECH_REGION
        );
        config.speechRecognitionLanguage = "ko-KR";
        speechConfigRef.current = config;

        // ìƒˆë¡œìš´ transcriber ìƒì„± ë° ì‹œì‘
        const newTranscriber = createTranscriber();
        if (newTranscriber) {
          transcriberRef.current = newTranscriber;
          await newTranscriber.startTranscribingAsync();
          setIsListening(true);
          appendLog("â–¶ï¸ ìë™ ì¬ì‹œì‘ ì™„ë£Œ");
        }
      } catch (e) {
        console.error("ìë™ ì¬ì‹œì‘ ì‹¤íŒ¨:", e);
        appendLog("âŒ ìë™ ì¬ì‹œì‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ");
        setIsListening(false);
      }
    };

    transcriber.canceled = restartHandler;

    return transcriber;
  };

  // ë…¹ìŒ ì‹œì‘/ì¤‘ì§€ ì œì–´
  useEffect(() => {
    const startTranscribing = async () => {
      if (!speechConfigRef.current) {
        setError("Speech configê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤");
        return;
      }

      try {
        const transcriber = createTranscriber();
        if (!transcriber) return;

        transcriberRef.current = transcriber;

        // ğŸ”„ RESTART ì‹œì—ë§Œ ìƒíƒœ ì´ˆê¸°í™” (Stopì€ ë¡œê·¸ ìœ ì§€)
        const hasExistingLogs = logsRef.current.length > 0;
        if (hasExistingLogs) {
          console.log("ğŸ”„ ì¬ì‹œì‘: ì´ì „ ë¡œê·¸ ì •ë¦¬ ì¤‘...");
          appendLog("ğŸ”„ ìƒˆë¡œìš´ ë…¹ìŒ ì„¸ì…˜ ì‹œì‘ - ì´ì „ ë¡œê·¸ ì •ë¦¬");
        }

        logsRef.current = [];
        setLogs([]);
        setTranscript([]);
        logCountRef.current = 0; // ë¡œê·¸ ì¹´ìš´í„° ë¦¬ì…‹

        await transcriber.startTranscribingAsync();
        setIsListening(true);
        appendLog("ğŸ¤ ì‹¤ì‹œê°„ ì „ì‚¬ ì‹œì‘");
        setError("");
        onRecordingStart(new Date());
        console.log("ğŸš€ ë…¹ìŒ ì‹œì‘ (restart ì •ë¦¬ ì™„ë£Œ):", new Date());
      } catch (err) {
        console.error("ì „ì‚¬ ì‹œì‘ ì‹¤íŒ¨:", err);
        setError("ìŒì„± ì¸ì‹ ì‹œì‘ ì‹¤íŒ¨");
        setIsListening(false);
      }
    };

    const stopTranscribing = async () => {
      if (transcriberRef.current) {
        try {
          // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì •ë¦¬
          transcriberRef.current.transcribed = () => {}; // ë¹ˆ í•¨ìˆ˜ë¡œ ì´ë²¤íŠ¸ ë¬´ì‹œ
          transcriberRef.current.canceled = () => {}; // ë¹ˆ í•¨ìˆ˜ë¡œ ì´ë²¤íŠ¸ ë¬´ì‹œ
          await transcriberRef.current.stopTranscribingAsync();
          transcriberRef.current = null;
          setIsListening(false);
          appendLog("ğŸ›‘ ì‹¤ì‹œê°„ ì „ì‚¬ ì¢…ë£Œ (ë¡œê·¸ ìœ ì§€)");
        } catch (err) {
          console.error("ì „ì‚¬ ì¢…ë£Œ ì‹¤íŒ¨:", err);
        }
      }
    };

    if (isRecording && !isListening && !transcriberRef.current) {
      // ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€: transcriberê°€ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì‹œì‘í•˜ì§€ ì•ŠìŒ
      startTranscribing();
    } else if (!isRecording && isListening) {
      stopTranscribing();
    }

    return () => {
      if (transcriberRef.current) {
        // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì •ë¦¬
        transcriberRef.current.transcribed = () => {}; // ë¹ˆ í•¨ìˆ˜ë¡œ ì´ë²¤íŠ¸ ë¬´ì‹œ
        transcriberRef.current.canceled = () => {}; // ë¹ˆ í•¨ìˆ˜ë¡œ ì´ë²¤íŠ¸ ë¬´ì‹œ
        transcriberRef.current.stopTranscribingAsync();
        transcriberRef.current = null;
      }
    };
  }, [isRecording, labelMap]); // labelMap ì˜ì¡´ì„± ì¶”ê°€

  // ìë™ ìŠ¤í¬ë¡¤
  useEffect(() => {
    transcriptEndRef.current?.scrollIntoView({ behavior: "smooth" });
  }, [logs]);

  return (
    <div
      className={sprinkles({
        backgroundColor: "neutral_1",
        borderRadius: "medium",
        padding: 16,
        borderColor: "neutral_2",
        borderWidth: "small",
      })}
      style={{
        maxHeight: "400px",
        overflowY: "auto",
      }}
    >
      {/* ìƒíƒœ í‘œì‹œ */}
      <div
        style={{
          display: "flex",
          alignItems: "center",
          justifyContent: "space-between",
          marginBottom: "16px",
          paddingBottom: "8px",
          borderBottom: "1px solid #e0e0e0",
        }}
      >
        <div style={{ display: "flex", alignItems: "center", gap: "8px" }}>
          {isListening && !isPaused ? (
            <Mic size={16} style={{ color: "#4CAF50" }} />
          ) : (
            <MicOff size={16} style={{ color: "#999" }} />
          )}
          <span
            className={sprinkles({
              fontSize: "small",
              color: "neutral_6",
            })}
          >
            {isListening && !isPaused
              ? "ì‹¤ì‹œê°„ ë…¹ìŒ ì¤‘..."
              : isListening && isPaused
              ? "ë…¹ìŒ ì¼ì‹œì •ì§€"
              : "ë…¹ìŒ ëŒ€ê¸°"}
          </span>
        </div>

        {currentSpeaker && (
          <div style={{ display: "flex", alignItems: "center", gap: "8px" }}>
            <Volume2 size={16} style={{ color: "#2196F3" }} />
            <span
              className={sprinkles({
                fontSize: "small",
                color: "primary",
              })}
            >
              {currentSpeaker}
            </span>
          </div>
        )}
      </div>

      {/* ì—ëŸ¬ í‘œì‹œ */}
      {error && (
        <div
          style={{
            display: "flex",
            alignItems: "center",
            gap: "8px",
            padding: "12px",
            backgroundColor: "#ffeaa7",
            borderRadius: "8px",
            marginBottom: "16px",
          }}
        >
          <AlertCircle size={16} style={{ color: "#d63031" }} />
          <span style={{ fontSize: "14px", color: "#2d3436" }}>{error}</span>
        </div>
      )}

      {/* ì „ì‚¬ ë‚´ìš© */}
      <div style={{ minHeight: "200px" }}>
        {logs.length === 0 ? (
          <div
            className={sprinkles({
              color: "neutral_4",
              padding: 40,
              fontSize: "small",
            })}
            style={{
              textAlign: "center",
            }}
          >
            {error
              ? "ì„¤ì •ì„ í™•ì¸í•œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”."
              : "íšŒì˜ ë‚´ìš©ì´ ì—¬ê¸°ì— ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤."}
          </div>
        ) : (
          <div style={{ fontSize: "14px", lineHeight: "1.6" }}>
            {logs.map((log, index) => {
              // ë¡œê·¸ íŒŒì‹±
              const timeMatch = log.match(/^\[(\d{2}:\d{2}:\d{2})\]/);
              const speakerMatch = log.match(/\]\[([^\]]+)\]/);
              const content = log.replace(/^\[.*?\]\[.*?\]\s*/, "");

              if (!content) return null;

              const time = timeMatch ? timeMatch[1] : "";
              const speaker = speakerMatch ? speakerMatch[1] : "System";
              const isSystemMessage =
                log.includes("ğŸ¤") ||
                log.includes("ğŸ›‘") ||
                log.includes("â¸ï¸") ||
                log.includes("â–¶ï¸") ||
                log.includes("âŒ");

              return (
                <div
                  key={index}
                  style={{
                    marginBottom: "12px",
                    padding: isSystemMessage ? "8px 12px" : "12px",
                    backgroundColor: isSystemMessage ? "#f8f9fa" : "#ffffff",
                    borderRadius: "8px",
                    borderLeft: isSystemMessage
                      ? "3px solid #6c757d"
                      : "3px solid #e6007e",
                  }}
                >
                  {isSystemMessage ? (
                    <div style={{ color: "#6c757d", fontStyle: "italic" }}>
                      {content}
                    </div>
                  ) : (
                    <>
                      <div
                        style={{
                          display: "flex",
                          alignItems: "center",
                          marginBottom: "4px",
                          gap: "8px",
                        }}
                      >
                        <div
                          style={{
                            width: "24px",
                            height: "24px",
                            borderRadius: "50%",
                            backgroundColor: "#e6007e",
                            color: "white",
                            display: "flex",
                            alignItems: "center",
                            justifyContent: "center",
                            fontSize: "12px",
                            fontWeight: "bold",
                          }}
                        >
                          {speaker.charAt(0)}
                        </div>
                        <span style={{ fontWeight: "500", fontSize: "14px" }}>
                          {speaker}
                        </span>
                        <span style={{ fontSize: "12px", color: "#666" }}>
                          {time}
                        </span>
                      </div>
                      <div style={{ paddingLeft: "32px", color: "#2d3436" }}>
                        {content}
                      </div>
                    </>
                  )}
                </div>
              );
            })}
          </div>
        )}
        <div ref={transcriptEndRef} />
      </div>
    </div>
  );
};

export default TranscriptionArea;
